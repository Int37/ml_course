{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа 10 (?? баллов). Предсказание победителя в Dota2.\n",
    "\n",
    "В этом финальном домашнем задании вы будет работать над более-менее реальными данными - сведениями из онлайн игры dota2. Примените все знания, которые вы полусили за этот семестр. Попробуйте сгенерировать разные признаки.\n",
    "\n",
    "По факту это перове соревнование в ML, в коттором мы предлагаем вам поучаствовать.\n",
    "\n",
    "Изначально это задание было в курсе \"Введение в машинное обучение\" от ВШЭ.\n",
    "\n",
    "## Задание\n",
    "\n",
    "1. Скачайте данные отсюда: https://inclass.kaggle.com/c/dota-2-win-probability-prediction (потребуется регистрация на kaggle) или из папки `data/dota2`.\n",
    "2. Прочитайте задание в файле `12-02-final-workshop`. Мы его не меняли и оставили таким, каким оно было в оригинальном курсе \"Введение в машинное обучение\".\n",
    "3. Проведите всё исследование в одном jupyter ноутбуке.\n",
    "5. Сохраниет решение в github и отправьте ссылку на ноутбук в eliademi.\n",
    "6. Потом вы получите на проверку ноутбук сокурсника и задание на проверку. Вам нужно будет проверить всё и оформить отчет, отправив его в виде текста на почту в ответ на письмо с заданием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "features=features.fillna(0)\n",
    "y = features['radiant_win']\n",
    "X = features =features.drop(['duration','radiant_win','duration',\n",
    " 'radiant_win',\n",
    " 'tower_status_radiant',\n",
    " 'tower_status_dire',\n",
    " 'barracks_status_radiant',\n",
    " 'barracks_status_dire'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26 s\n",
      "10 [0.66383799 0.66635457 0.66360048 0.66529818 0.66516222] 0.6648506879750012\n",
      "Wall time: 50.6 s\n",
      "20 [0.68083889 0.68272733 0.67969876 0.6834932  0.6855512 ] 0.6824618768044435\n",
      "Wall time: 1min 11s\n",
      "30 [0.68892093 0.68934663 0.68712298 0.69180598 0.69283583] 0.6900064710388155\n",
      "Wall time: 1min 34s\n",
      "40 [0.69264125 0.69335305 0.69153074 0.69586466 0.69680392] 0.6940387245121105\n",
      "Wall time: 1min 56s\n",
      "50 [0.69627399 0.69747879 0.69470891 0.69921915 0.69979097] 0.6974943609466162\n",
      "Wall time: 2min 19s\n",
      "60 [0.69904111 0.69974831 0.69741008 0.70187297 0.70252411] 0.7001193156741052\n",
      "Wall time: 2min 42s\n",
      "70 [0.70120426 0.7018134  0.699683   0.70399032 0.70389172] 0.7021165414535407\n",
      "Wall time: 3min 5s\n",
      "80 [0.70273274 0.70352284 0.70166409 0.70536378 0.70579495] 0.7038156791465111\n",
      "Wall time: 3min 28s\n",
      "90 [0.70428355 0.70489618 0.70314489 0.70636257 0.70710108] 0.7051576546297991\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 100, 10):\n",
    "    model = GradientBoostingClassifier(n_estimators=i, random_state=42)\n",
    "    %time result=cross_val_score(model,X,y,scoring=\"roc_auc\",cv = KFold(n_splits=5, random_state=42, shuffle=True))\n",
    "    print(i,result,result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем увеличить количество глубины деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68102708, 0.68164015, 0.67687357, 0.68110657, 0.68104133])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=10, random_state=42,max_depth=10)\n",
    "result=cross_val_score(model,X,y,scoring=\"roc_auc\",cv = KFold(n_splits=5, random_state=42, shuffle=True))\n",
    "result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Результат оказался удовлетворительным,качество улучшилось на 10 деревьях,понижаем количество деревьев,относительно повышения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68433689, 0.68554282, 0.68026239, 0.68572485, 0.68804223])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = GradientBoostingClassifier(n_estimators=10, random_state=42,max_depth = 6)\n",
    "result=cross_val_score(model,X,y,scoring=\"roc_auc\",cv = KFold(n_splits=5, random_state=42, shuffle=True))\n",
    "result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "еще более лучший результат,далее я попробовал обучить на 1000 деревьях,с глубиной в 6,но это дало худший результат относительно 1000 деревьях с глубиной 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.72392892, 0.72267035, 0.72333701, 0.72710896, 0.72504246])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = GradientBoostingClassifier(n_estimators=1000, random_state=42,max_depth = 3)\n",
    "%time result=cross_val_score(model,X,y,scoring=\"roc_auc\",cv = KFold(n_splits=5, random_state=42, shuffle=True))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 43min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.72513551, 0.72346132, 0.72400844, 0.72795167, 0.72549135])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = GradientBoostingClassifier(n_estimators=1300, random_state=42,max_depth = 3)\n",
    "%time result=cross_val_score(model,features,true_result,scoring=\"roc_auc\",cv = KFold(n_splits=5, random_state=42, shuffle=True))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОТЧЕТ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие признаки имеют пропуски среди своих значений? Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)?\n",
    "\n",
    "radiant_first_ward_time ,dire_flying_courier_time и т.д. Что значит что отсутствует время постановки 1 варда у сил света ? Очень просто - значит что она не ставили вард за первые 5 минут\n",
    "Что значит что отсутствует время апа курицы у сил тьмы ? Очень просто - у сил тьмы курицу не апали в первые 5 минут,видимо задания старое,ибо сейчас в доте автоап курьера по таймингу\n",
    "\n",
    "\n",
    "\n",
    "Как называется столбец, содержащий целевую переменную?\n",
    "\n",
    "'radiant_win'\n",
    "\n",
    "\n",
    "Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? Инструкцию по измерению времени можно найти ниже по тексту. Какое качество при этом получилось? Напомним, что в данном задании мы используем метрику качества AUC-ROC.\n",
    "\n",
    "Wall time: 3min 25s,0.689188702\n",
    "\n",
    "\n",
    "Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что бы вы предложили делать, чтобы ускорить его обучение при увеличении количества деревьев?\n",
    "\n",
    "\n",
    "Да,имеет смысл,ведь это дает лучший результат. Ускорить процесс можно увеличениям числа деревьев и ограничением количества признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['start_time',\n",
       " 'lobby_type',\n",
       " 'r1_hero',\n",
       " 'r1_level',\n",
       " 'r1_xp',\n",
       " 'r1_gold',\n",
       " 'r1_lh',\n",
       " 'r1_kills',\n",
       " 'r1_deaths',\n",
       " 'r1_items',\n",
       " 'r2_hero',\n",
       " 'r2_level',\n",
       " 'r2_xp',\n",
       " 'r2_gold',\n",
       " 'r2_lh',\n",
       " 'r2_kills',\n",
       " 'r2_deaths',\n",
       " 'r2_items',\n",
       " 'r3_hero',\n",
       " 'r3_level',\n",
       " 'r3_xp',\n",
       " 'r3_gold',\n",
       " 'r3_lh',\n",
       " 'r3_kills',\n",
       " 'r3_deaths',\n",
       " 'r3_items',\n",
       " 'r4_hero',\n",
       " 'r4_level',\n",
       " 'r4_xp',\n",
       " 'r4_gold',\n",
       " 'r4_lh',\n",
       " 'r4_kills',\n",
       " 'r4_deaths',\n",
       " 'r4_items',\n",
       " 'r5_hero',\n",
       " 'r5_level',\n",
       " 'r5_xp',\n",
       " 'r5_gold',\n",
       " 'r5_lh',\n",
       " 'r5_kills',\n",
       " 'r5_deaths',\n",
       " 'r5_items',\n",
       " 'd1_hero',\n",
       " 'd1_level',\n",
       " 'd1_xp',\n",
       " 'd1_gold',\n",
       " 'd1_lh',\n",
       " 'd1_kills',\n",
       " 'd1_deaths',\n",
       " 'd1_items',\n",
       " 'd2_hero',\n",
       " 'd2_level',\n",
       " 'd2_xp',\n",
       " 'd2_gold',\n",
       " 'd2_lh',\n",
       " 'd2_kills',\n",
       " 'd2_deaths',\n",
       " 'd2_items',\n",
       " 'd3_hero',\n",
       " 'd3_level',\n",
       " 'd3_xp',\n",
       " 'd3_gold',\n",
       " 'd3_lh',\n",
       " 'd3_kills',\n",
       " 'd3_deaths',\n",
       " 'd3_items',\n",
       " 'd4_hero',\n",
       " 'd4_level',\n",
       " 'd4_xp',\n",
       " 'd4_gold',\n",
       " 'd4_lh',\n",
       " 'd4_kills',\n",
       " 'd4_deaths',\n",
       " 'd4_items',\n",
       " 'd5_hero',\n",
       " 'd5_level',\n",
       " 'd5_xp',\n",
       " 'd5_gold',\n",
       " 'd5_lh',\n",
       " 'd5_kills',\n",
       " 'd5_deaths',\n",
       " 'd5_items',\n",
       " 'first_blood_time',\n",
       " 'first_blood_team',\n",
       " 'first_blood_player1',\n",
       " 'first_blood_player2',\n",
       " 'radiant_bottle_time',\n",
       " 'radiant_courier_time',\n",
       " 'radiant_flying_courier_time',\n",
       " 'radiant_tpscroll_count',\n",
       " 'radiant_boots_count',\n",
       " 'radiant_ward_observer_count',\n",
       " 'radiant_ward_sentry_count',\n",
       " 'radiant_first_ward_time',\n",
       " 'dire_bottle_time',\n",
       " 'dire_courier_time',\n",
       " 'dire_flying_courier_time',\n",
       " 'dire_tpscroll_count',\n",
       " 'dire_boots_count',\n",
       " 'dire_ward_observer_count',\n",
       " 'dire_ward_sentry_count',\n",
       " 'dire_first_ward_time']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ 'r1_hero',\n",
    " 'r1_items',\n",
    " 'lobby_type',]\n",
    "drop = []\n",
    "for i in range(1,6):\n",
    "    drop.append('r' + str(i) + '_hero')\n",
    "    drop.append('r' + str (i) + '_items')\n",
    "    drop.append('d' + str(i) + '_hero')\n",
    "    drop.append('d' + str (i) + '_items')\n",
    "drop.append('lobby_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.drop(drop,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\conda\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71323281 0.71547263 0.71508284 0.71647939 0.71760167]\n",
      "[0.71323208 0.71546894 0.71507682 0.71648028 0.71759587]\n",
      "[0.71323154 0.71546946 0.71507644 0.71648089 0.71759482]\n",
      "[0.71323084 0.7154668  0.71507582 0.71648183 0.71759327]\n",
      "[0.71323053 0.71546696 0.71507533 0.71648347 0.7175934 ]\n",
      "[0.71323016 0.71546907 0.71507565 0.71648311 0.71759238]\n",
      "[0.71322995 0.71546912 0.71507556 0.71648342 0.71759163]\n",
      "[0.71323081 0.71546945 0.71507558 0.71648406 0.71759148]\n",
      "[0.71323078 0.71546963 0.71507566 0.71648432 0.71759359]\n",
      "[0.71323075 0.71546946 0.71507538 0.71648412 0.71759283]\n",
      "[0.7132304  0.71546951 0.71507521 0.71648382 0.71759276]\n",
      "[0.71323033 0.71546926 0.71507509 0.71648393 0.71759286]\n",
      "[0.71323027 0.71546922 0.71507499 0.71648408 0.71759287]\n",
      "[0.71323028 0.71546926 0.71507479 0.71648404 0.71759306]\n",
      "[0.71323028 0.7154692  0.71507476 0.71648404 0.71759305]\n",
      "[0.71323034 0.7154692  0.71507476 0.71648387 0.71759306]\n",
      "[0.71323053 0.71546924 0.71507468 0.71648389 0.71759306]\n",
      "[0.71323053 0.71546925 0.71507472 0.71648392 0.71759296]\n",
      "[0.71323048 0.71546931 0.71507477 0.71648395 0.71759302]\n",
      "[0.71323056 0.71546923 0.71507473 0.71648402 0.71759302]\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,4,0.2):\n",
    "    model = LogisticRegression(random_state=42, C=i, penalty='l2',solver = 'lbfgs')\n",
    "    print(cross_val_score(model, x, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n",
      "[0.51184163 0.51560696 0.51597178 0.50921324 0.51460449]\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,4,0.2):\n",
    "    model = LogisticRegression(random_state=42, C=i, penalty='l2',solver ='lbfgs')\n",
    "    print(cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "k =features['d1_hero']\n",
    "N = k.unique().size \n",
    "print(N)\n",
    "N = k.unique().max()\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# N — количество различных героев в выборке\n",
    "N = 112\n",
    "data = features\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9   ...   102  103  \\\n",
       "match_id                                                   ...              \n",
       "0         0.0  0.0  0.0 -1.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0   \n",
       "1         0.0  0.0  0.0  0.0  0.0  0.0 -1.0  0.0  0.0  0.0 ...   0.0  0.0   \n",
       "2         0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0   \n",
       "3         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0   \n",
       "4         0.0  0.0  0.0  0.0  0.0  0.0  0.0 -1.0  0.0  0.0 ...   0.0  0.0   \n",
       "\n",
       "          104  105  106  107  108  109  110  111  \n",
       "match_id                                          \n",
       "0         1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = features\n",
    "df_pick = pd.DataFrame(data=X_pick, index=df.index)\n",
    "df_pick.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(X, df_pick, left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(drop,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\conda\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in np.arange(0.01,0.5,0.06):\n",
    "    model = LogisticRegression(random_state=42, C=i, penalty='l2',solver ='lbfgs')\n",
    "    res.append(cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74825566 0.75244183 0.74822701 0.75499765 0.7507122 ] 0.7509268697322797\n",
      "[0.74825533 0.75243906 0.74822432 0.75499204 0.7507054 ] 0.7509232281599376\n",
      "[0.74825602 0.75244003 0.74822321 0.75498933 0.75070392] 0.7509225015747417\n",
      "[0.74825465 0.75243871 0.74822422 0.75498898 0.75070295] 0.7509219019535127\n",
      "[0.74825531 0.75244081 0.74822265 0.75498823 0.75070241] 0.7509218829306203\n",
      "[0.74825464 0.75244059 0.74822292 0.75498845 0.75070194] 0.7509217091678566\n",
      "[0.74825465 0.75244021 0.74822114 0.75498864 0.75070172] 0.7509212728293104\n",
      "[0.74825507 0.75243985 0.74822157 0.75498875 0.75070161] 0.7509213702939525\n",
      "[0.74825517 0.75243976 0.74822241 0.75498872 0.75070168] 0.7509215482255692\n",
      "[0.74825444 0.75243974 0.74822196 0.75498892 0.75070163] 0.7509213384700001\n",
      "[0.74825455 0.75243978 0.74822189 0.75498852 0.75070144] 0.7509212367902587\n",
      "[0.74825429 0.75243982 0.74822242 0.75498851 0.75070147] 0.7509213024295861\n",
      "[0.74825452 0.75243972 0.74822117 0.75498861 0.75070143] 0.7509210906392645\n",
      "[0.74825457 0.75243876 0.74822145 0.7549885  0.75070152] 0.7509209593093299\n",
      "[0.74825463 0.75243889 0.74822136 0.75498838 0.75070142] 0.750920936009414\n",
      "[0.7482547  0.7524389  0.7482211  0.75498846 0.75070138] 0.7509209063625505\n",
      "[0.74825481 0.75243893 0.74822115 0.75498838 0.75070136] 0.7509209254330368\n",
      "[0.74825488 0.75243894 0.74822204 0.75498843 0.75070139] 0.7509211351348537\n",
      "[0.74825492 0.75243902 0.74822226 0.75498834 0.75070127] 0.7509211647855458\n",
      "[0.74825484 0.75243901 0.74822171 0.75498837 0.75070125] 0.7509210376917823\n"
     ]
    }
   ],
   "source": [
    "for i in res:\n",
    "    print(i,i.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет 2\n",
    "Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?\n",
    "\n",
    "0.71556599,результат похуже,чем с 1000 деревьями,но лучше чем градиентный бустинг с меньшим количеством деревьев,например 100,но логистическая регрессия значительно быстрее\n",
    "\n",
    "\n",
    "Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение?\n",
    "\n",
    "\n",
    "Положительно,ведь в регрессивные модели линейны,а категориальные признаки не несут в себе никакого значения,как измеримые,поэтому они лишь путают алгоритм\n",
    "\n",
    "\n",
    "Сколько различных идентификаторов героев существует в данной игре?\n",
    "108\n",
    "\n",
    "Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить?\n",
    "\n",
    "качество улучшилось с 0.71556599 до 0.7509210376917823,что очень круто,целых 4 процента.Некоторые герои статистически имеют выше винрейт,поэтому то,какие герои участвует в игре очень важная информация,как категориальный признак она не несла положительную нагрузку для регрессии,но мешок слов,как бинарный признак несет в себе положительную нагрузку для регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# другие методы "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RidgeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto [0.74818862 0.75242903 0.74797957 0.75487812 0.75060998] 0.7508170651200416\n",
      "svd [0.74818862 0.75242903 0.74797957 0.75487812 0.75060998] 0.7508170651200416\n",
      "cholesky [0.74818862 0.75242903 0.74797957 0.75487812 0.75060998] 0.7508170651200416\n",
      "lsqr [0.74823603 0.75261207 0.7479658  0.75509892 0.75067078] 0.7509167193246931\n",
      "sparse_cg [0.74817106 0.75244081 0.74796703 0.75489773 0.7506146 ] 0.7508182463836514\n",
      "sag [0.7481832  0.75242972 0.74797658 0.75487695 0.75061304] 0.7508158976551604\n",
      "saga [0.74818681 0.75242998 0.74797906 0.75488013 0.75061023] 0.7508172429609895\n"
     ]
    }
   ],
   "source": [
    "solv=['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "for k in solv:\n",
    "    model = RidgeClassifier(alpha = 1,solver=k,random_state=42)\n",
    "    res=cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "    print(k,res,res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48999999999999994 [0.74826748 0.75261403 0.74796396 0.75510867 0.75066997] 0.7509248242567688\n"
     ]
    }
   ],
   "source": [
    "model = RidgeClassifier(alpha = 1,solver='lsqr',random_state=42)\n",
    "res=cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "print(res,res.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# randomforest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators= 100,random_state=42)\n",
    "res=cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69019233 0.69386827 0.69261046 0.69257733 0.69769604] 0.693388886426866\n"
     ]
    }
   ],
   "source": [
    "print(res,res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 5min 43s\n",
      "[0.70471013 0.70779522 0.705266   0.70650047 0.70977769] 0.7068099038933443\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators= 1300,random_state=42)\n",
    "%time res=cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "print(res,res.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesianRidge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.750871830597536,\n",
       " array([0.74821581, 0.75239536, 0.74804434, 0.75498169, 0.75072195]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  linear_model.BayesianRidge()\n",
    "res =cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "res.mean(),res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавляем колонки ,произведения колонок\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "features=features.fillna(0)\n",
    "y = features['radiant_win']\n",
    "X = features.drop(['duration','radiant_win','duration',\n",
    " 'radiant_win',\n",
    " 'tower_status_radiant',\n",
    " 'tower_status_dire',\n",
    " 'barracks_status_radiant',\n",
    " 'barracks_status_dire'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# N — количество различных героев в выборке\n",
    "N = 112\n",
    "data = features\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ 'r1_hero',\n",
    " 'r1_items',\n",
    " 'lobby_type',]\n",
    "drop = ['lobby_type']\n",
    "for i in range(1,6):\n",
    "    drop.append('r' + str(i) + '_hero')\n",
    "    drop.append('r' + str (i) + '_items')\n",
    "    drop.append('d' + str(i) + '_hero')\n",
    "    drop.append('d' + str (i) + '_items')\n",
    "X = X.drop(drop,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = features\n",
    "df_pick = pd.DataFrame(data=X_pick, index=df.index)\n",
    "df_pick.head()\n",
    "X = pd.merge(X, df_pick, left_index=True, right_index=True, how='outer')\n",
    "for p in range(1,6):\n",
    "    X['r'+str(p)+'_gold_level' ] = X['r'+str(p)+'_gold' ] * X['r'+str(p)+'_level' ]\n",
    "    X['d'+str(p)+'_gold_level' ] = -1 * X['d'+str(p)+'_gold' ] * X['d'+str(p)+'_level' ]\n",
    "    X['r'+str(p)+'_kills_deaths' ] =  X['r'+str(p)+'_kills' ] * X['r'+str(p)+'_deaths' ]\n",
    "    X['d'+str(p)+'_kills_deaths' ] = -1* X['d'+str(p)+'_kills' ] * X['d'+str(p)+'_deaths' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\conda\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74920892 0.75386207 0.74847277 0.75594407 0.75158645] 0.7518148552953432\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, C=0.06, penalty='l2',solver ='lbfgs')\n",
    "res = cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "print(res,res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7517493767053145,\n",
       " array([0.74913538, 0.75359872, 0.74849248, 0.75589744, 0.75162286]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model =  linear_model.BayesianRidge()\n",
    "res =cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "res.mean(),res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем поудалять колонки,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "выберем самые невлияющие на исход матча колонки,по моему опыту игры "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\conda\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "features=features.fillna(0)\n",
    "y = features['radiant_win']\n",
    "X = features.drop(['duration','radiant_win','duration',\n",
    " 'radiant_win',\n",
    " 'tower_status_radiant',\n",
    " 'tower_status_dire',\n",
    " 'barracks_status_radiant',\n",
    " 'barracks_status_dire'],axis=1)\n",
    "# N — количество различных героев в выборке\n",
    "N = 112\n",
    "data = features\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "drop = ['lobby_type']\n",
    "for i in range(1,6):\n",
    "    drop.append('r' + str(i) + '_hero')\n",
    "    drop.append('r' + str (i) + '_items')\n",
    "    drop.append('d' + str(i) + '_hero')\n",
    "    drop.append('d' + str (i) + '_items')\n",
    "X = X.drop(drop,axis = 1)\n",
    "drop = [ 'dire_courier_time' ,'first_blood_player1','first_blood_player2','radiant_bottle_time','dire_bottle_time','start_time']\n",
    "\n",
    "X = X.drop(drop,axis = 1)\n",
    "X.columns\n",
    "df = features\n",
    "df_pick = pd.DataFrame(data=X_pick, index=df.index)\n",
    "df_pick.head()\n",
    "X = pd.merge(X, df_pick, left_index=True, right_index=True, how='outer')\n",
    "for p in range(1,6):\n",
    "    X['r'+str(p)+'_gold_level' ] = X['r'+str(p)+'_gold' ] * X['r'+str(p)+'_level' ]\n",
    "    X['d'+str(p)+'_gold_level' ] = -1 * X['d'+str(p)+'_gold' ] * X['d'+str(p)+'_level' ]\n",
    "    X['r'+str(p)+'_kills_deaths' ] =  X['r'+str(p)+'_kills' ] * X['r'+str(p)+'_deaths' ]\n",
    "    X['d'+str(p)+'_kills_deaths' ] = -1* X['d'+str(p)+'_kills' ] * X['d'+str(p)+'_deaths' ]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74895486 0.75369777 0.74816655 0.75581765 0.75128847] 0.7515850593297878\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, C=0.06, penalty='l2',solver ='lbfgs')\n",
    "res = cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "print(res,res.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "качество ухудшилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\conda\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "features=features.fillna(0)\n",
    "y = features['radiant_win']\n",
    "X = features.drop(['duration','radiant_win','duration',\n",
    " 'radiant_win',\n",
    " 'tower_status_radiant',\n",
    " 'tower_status_dire',\n",
    " 'barracks_status_radiant',\n",
    " 'barracks_status_dire'],axis=1)\n",
    "# N — количество различных героев в выборке\n",
    "N = 112\n",
    "data = features\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "drop = ['lobby_type']\n",
    "for i in range(1,6):\n",
    "    drop.append('r' + str(i) + '_hero')\n",
    "    drop.append('r' + str (i) + '_items')\n",
    "    drop.append('d' + str(i) + '_hero')\n",
    "    drop.append('d' + str (i) + '_items')\n",
    "X = X.drop(drop,axis = 1)\n",
    "drop = [ 'dire_courier_time' ,'first_blood_player1','first_blood_player2','start_time']\n",
    "\n",
    "\n",
    "X = X.drop(drop,axis = 1)\n",
    "X.columns\n",
    "df = features\n",
    "df_pick = pd.DataFrame(data=X_pick, index=df.index)\n",
    "df_pick.head()\n",
    "X = pd.merge(X, df_pick, left_index=True, right_index=True, how='outer')\n",
    "for p in range(1,6):\n",
    "    X['r'+str(p)+'_gold_level' ] = X['r'+str(p)+'_gold' ] * X['r'+str(p)+'_level' ]\n",
    "    X['d'+str(p)+'_gold_level' ] = -1 * X['d'+str(p)+'_gold' ] * X['d'+str(p)+'_level' ]\n",
    "    X['r'+str(p)+'_kills_deaths' ] =  X['r'+str(p)+'_kills' ] * X['r'+str(p)+'_deaths' ]\n",
    "    X['d'+str(p)+'_kills_deaths' ] = -1* X['d'+str(p)+'_kills' ] * X['d'+str(p)+'_deaths' ]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74897236 0.7536677  0.74811437 0.75581129 0.7512601 ] 0.7515651657944492\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, C=0.06, penalty='l2',solver ='lbfgs')\n",
    "res = cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "print(res,res.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "до сих пор,ухудшилось,надо дропать меньше признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\conda\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "features=features.fillna(0)\n",
    "y = features['radiant_win']\n",
    "X = features.drop(['duration','radiant_win','duration',\n",
    " 'radiant_win',\n",
    " 'tower_status_radiant',\n",
    " 'tower_status_dire',\n",
    " 'barracks_status_radiant',\n",
    " 'barracks_status_dire'],axis=1)\n",
    "# N — количество различных героев в выборке\n",
    "N = 112\n",
    "data = features\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "drop = ['lobby_type']\n",
    "for i in range(1,6):\n",
    "    drop.append('r' + str(i) + '_hero')\n",
    "    drop.append('r' + str (i) + '_items')\n",
    "    drop.append('d' + str(i) + '_hero')\n",
    "    drop.append('d' + str (i) + '_items')\n",
    "X = X.drop(drop,axis = 1)\n",
    "drop = [ 'dire_courier_time' ,'first_blood_player1']\n",
    "\n",
    "\n",
    "X = X.drop(drop,axis = 1)\n",
    "X.columns\n",
    "df = features\n",
    "df_pick = pd.DataFrame(data=X_pick, index=df.index)\n",
    "df_pick.head()\n",
    "X = pd.merge(X, df_pick, left_index=True, right_index=True, how='outer')\n",
    "for p in range(1,6):\n",
    "    X['r'+str(p)+'_gold_level' ] = X['r'+str(p)+'_gold' ] * X['r'+str(p)+'_level' ]\n",
    "    X['d'+str(p)+'_gold_level' ] = -1 * X['d'+str(p)+'_gold' ] * X['d'+str(p)+'_level' ]\n",
    "    X['r'+str(p)+'_kills_deaths' ] =  X['r'+str(p)+'_kills' ] * X['r'+str(p)+'_deaths' ]\n",
    "    X['d'+str(p)+'_kills_deaths' ] = -1* X['d'+str(p)+'_kills' ] * X['d'+str(p)+'_deaths' ]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74911401 0.75384221 0.74846374 0.7558374  0.7513697 ] 0.7517254131905122\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, C=0.06, penalty='l2',solver ='lbfgs')\n",
    "res = cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "print(res,res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7516458215136634,\n",
       " array([0.74896265, 0.75359916, 0.74846426, 0.75578403, 0.75141902]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  linear_model.BayesianRidge()\n",
    "res =cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "res.mean(),res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\conda\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\conda\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "features=features.fillna(0)\n",
    "y = features['radiant_win']\n",
    "X = features.drop(['duration','radiant_win','duration',\n",
    " 'radiant_win',\n",
    " 'tower_status_radiant',\n",
    " 'tower_status_dire',\n",
    " 'barracks_status_radiant',\n",
    " 'barracks_status_dire'],axis=1)\n",
    "# N — количество различных героев в выборке\n",
    "N = 112\n",
    "data = features\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "drop = ['lobby_type']\n",
    "for i in range(1,6):\n",
    "    drop.append('r' + str(i) + '_hero')\n",
    "    drop.append('r' + str (i) + '_items')\n",
    "    drop.append('d' + str(i) + '_hero')\n",
    "    drop.append('d' + str (i) + '_items')\n",
    "X = X.drop(drop,axis = 1)\n",
    "drop = [ 'dire_courier_time' ,'first_blood_player1']\n",
    "\n",
    "\n",
    "X = X.drop(drop,axis = 1)\n",
    "X.columns\n",
    "df = features\n",
    "df_pick = pd.DataFrame(data=X_pick, index=df.index)\n",
    "df_pick.head()\n",
    "X = pd.merge(X, df_pick, left_index=True, right_index=True, how='outer')\n",
    "for p in range(1,6):\n",
    "    X['r'+str(p)+'_gold_level' ] = X['r'+str(p)+'_gold' ] * X['r'+str(p)+'_level' ]\n",
    "    X['d'+str(p)+'_gold_level' ] = -1 * X['d'+str(p)+'_gold' ] * X['d'+str(p)+'_level' ]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74921762 0.75381348 0.74848352 0.75581569 0.75147748] 0.7517615571289387\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, C=0.06, penalty='l2',solver ='lbfgs')\n",
    "res = cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "print(res,res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "features=features.fillna(0)\n",
    "y = features['radiant_win']\n",
    "X = features.drop(['duration','radiant_win','duration',\n",
    " 'radiant_win',\n",
    " 'tower_status_radiant',\n",
    " 'tower_status_dire',\n",
    " 'barracks_status_radiant',\n",
    " 'barracks_status_dire'],axis=1)\n",
    "# N — количество различных героев в выборке\n",
    "N = 112\n",
    "data = features\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "drop = ['lobby_type']\n",
    "for i in range(1,6):\n",
    "    drop.append('r' + str(i) + '_hero')\n",
    "    drop.append('r' + str (i) + '_items')\n",
    "    drop.append('d' + str(i) + '_hero')\n",
    "    drop.append('d' + str (i) + '_items')\n",
    "X = X.drop(drop,axis = 1)\n",
    "drop = [ 'dire_courier_time' ,'first_blood_player1']\n",
    "\n",
    "\n",
    "X = X.drop(drop,axis = 1)\n",
    "X.columns\n",
    "df = features\n",
    "df_pick = pd.DataFrame(data=X_pick, index=df.index)\n",
    "df_pick.head()\n",
    "X = pd.merge(X, df_pick, left_index=True, right_index=True, how='outer')\n",
    "for p in range(1,6):\n",
    "    X['r'+str(p)+'_kills_deaths' ] =  X['r'+str(p)+'_kills' ] * X['r'+str(p)+'_deaths' ]\n",
    "    X['d'+str(p)+'_kills_deaths' ] = -1* X['d'+str(p)+'_kills' ] * X['d'+str(p)+'_deaths' ]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74921762 0.75381348 0.74848352 0.75581569 0.75147748] 0.7517615571289387\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, C=0.06, penalty='l2',solver ='lbfgs')\n",
    "res = cross_val_score(model, X, y, cv=KFold(n_splits=5, random_state=42, shuffle=True), scoring=\"roc_auc\")\n",
    "print(res,res.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "попробовал добавить лишь 1 перемножения,убрав другое,толку не особо\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Возможно мне бы стоило обрамить в функцию код,который я так долго копипастил у себя ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# В любой непонятной ситуации стоит использовать нейросеть ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy\n",
    " \n",
    "\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(194, input_dim=194, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=3, batch_size=10, verbose=1)\n",
    "%time kfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "%time results = cross_val_score(model, X, y, cv=kfold,scoring=\"roc_auc\")\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU times: user 25 µs, sys: 3 µs, total: 28 µs\n",
    "Wall time: 34.8 µs\n",
    "Epoch 1/3\n",
    "77783/77783 [==============================] - 37s 475us/step - loss: 0.6063 - acc: 0.6669\n",
    "Epoch 2/3\n",
    "77783/77783 [==============================] - 36s 464us/step - loss: 0.5864 - acc: 0.6853\n",
    "Epoch 3/3\n",
    "77783/77783 [==============================] - 36s 461us/step - loss: 0.5774 - acc: 0.6931\n",
    "19447/19447 [==============================] - 3s 146us/step\n",
    "Epoch 1/3\n",
    "77784/77784 [==============================] - 37s 480us/step - loss: 0.6069 - acc: 0.6650\n",
    "Epoch 2/3\n",
    "77784/77784 [==============================] - 36s 463us/step - loss: 0.5872 - acc: 0.6838\n",
    "Epoch 3/3\n",
    "77784/77784 [==============================] - 36s 465us/step - loss: 0.5772 - acc: 0.6926\n",
    "19446/19446 [==============================] - 3s 152us/step\n",
    "Epoch 1/3\n",
    "77784/77784 [==============================] - 38s 485us/step - loss: 0.6062 - acc: 0.6680\n",
    "Epoch 2/3\n",
    "77784/77784 [==============================] - 37s 470us/step - loss: 0.5863 - acc: 0.6855\n",
    "Epoch 3/3\n",
    "77784/77784 [==============================] - 37s 470us/step - loss: 0.5764 - acc: 0.6942\n",
    "19446/19446 [==============================] - 3s 154us/step\n",
    "Epoch 1/3\n",
    "77784/77784 [==============================] - 38s 485us/step - loss: 0.6046 - acc: 0.6687\n",
    "Epoch 2/3\n",
    "77784/77784 [==============================] - 36s 467us/step - loss: 0.5854 - acc: 0.6854\n",
    "Epoch 3/3\n",
    "77784/77784 [==============================] - 36s 468us/step - loss: 0.5764 - acc: 0.6919\n",
    "19446/19446 [==============================] - 3s 159us/step\n",
    "Epoch 1/3\n",
    "77785/77785 [==============================] - 38s 485us/step - loss: 0.6040 - acc: 0.6666\n",
    "Epoch 2/3\n",
    "77785/77785 [==============================] - 36s 467us/step - loss: 0.5856 - acc: 0.6874\n",
    "Epoch 3/3\n",
    "77785/77785 [==============================] - 36s 469us/step - loss: 0.5762 - acc: 0.6932\n",
    "19445/19445 [==============================] - 3s 164us/step\n",
    "CPU times: user 11min, sys: 1min 21s, total: 12min 22s\n",
    "Wall time: 9min 28s\n",
    "0.7434216633291358"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не самый плохой результат(код исполнялся на сервере гугл,т.к. у меня керас решил не работать),изначально использовал другую модель и выдало 0.697150825884162,в целом ужасное значения переобучения,лишь поигравшись с некоторыми параметрами что то вышло,хотя хотелось бы получить результат лучше,но тут нужно больше практиковаться"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
